{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = []\n",
    "fmask = '/home/mila/reit/*.xls*' \n",
    "\n",
    "for f in glob.glob(fmask): \n",
    "    df = pd.read_excel(f)\n",
    "    comp = df.iloc[0,0]\n",
    "    df.dropna(subset = [\"Unnamed: 1\"], inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop([0]).reset_index(drop=True)\n",
    "    df1 = df.loc[df['Unnamed: 0'].str.contains('   ')]\n",
    "    df2 = df.loc[~df['Unnamed: 0'].str.contains('   ')]\n",
    "    l = list(df2.index.values.tolist())\n",
    "    l_mod = [0] + l + [max(l)+len(df)-1]\n",
    "    list_of_dfs = [df.iloc[l_mod[n]:l_mod[n+1]] for n in range(len(l_mod)-1)]\n",
    "    for li in np.arange(1,(len(l)+1)):\n",
    "        list_of_dfs[li]['segment'] = list_of_dfs[li].iloc[0,0]\n",
    "        list_of_dfs[li] = list_of_dfs[li].reset_index(drop=True)\n",
    "        list_of_dfs[li] = list_of_dfs[li].drop([0])\n",
    "    df3 = pd.concat(list_of_dfs).reset_index(drop=True)\n",
    "    df3['MSA'] = df3['Unnamed: 0']\n",
    "    #not USA\n",
    "    df4 = df3[df3['MSA'].str.contains('USA')==False]\n",
    "    if  (df4['MSA'].str.contains(',')).any():\n",
    "        df4[['city','country']] = df4['MSA'].str.split(', ',expand=True)\n",
    "        df4['state'] = 0\n",
    "        df4.loc[df4.index[df4['country'].isnull()].tolist(),'state'] = df4['city']\n",
    "        df4.loc[df4.index[df4['country'].isnull()].tolist(),'city'] = ' '\n",
    "        df4.loc[df4.index[df4['country'].isnull()].tolist(),'country'] = df4['state']\n",
    "        df4['state'] = ''\n",
    "    elif (df4['MSA'].str.contains(',')==False).any():\n",
    "        df4['country'] = df4['MSA']\n",
    "        df4['state'] = ''\n",
    "        df4['city'] = ''\n",
    "    #USA\n",
    "    if (df3['MSA'].str.contains('USA')).any():\n",
    "        df5 = df3[df3['MSA'].str.contains('USA')]\n",
    "        df5[['city','state','country']] = df5['MSA'].str.split(', ',expand=True)\n",
    "        df5 = df5.replace(np.nan, '', regex=True)\n",
    "        df5.loc[df5.index[df5['state'].str.contains('USA')].tolist(),'country']=df5['state']\n",
    "        df5['state_add']=df5['state']\n",
    "        df5.loc[df5.index[df5['state_add'].str.contains('USA')].tolist(),'state']=df5['city']\n",
    "        df5.loc[df5.index[df5['state_add'].str.contains('USA')].tolist(),'city']=' '\n",
    "        del df5['state_add']\n",
    "        df5.loc[df5.index[df5['city'].str.contains('USA')].tolist(),'country']=df5['city']\n",
    "        df5.loc[df5.index[df5['city'].str.contains('USA')].tolist(),'city']=' '\n",
    "        df3 = df5.append(df4, ignore_index=True)\n",
    "    elif (df3['MSA'].str.contains('USA')==False).any():\n",
    "        df3 = df4\n",
    "    \n",
    "    df3['REITS'] = comp\n",
    "    df3[\"REITS\"] = df3[\"REITS\"].str.split(\"|\", expand=True)[0]\n",
    "    df3['number'] = df3['Unnamed: 1']\n",
    "    df3['owned_size_size'] = df3['Unnamed: 2']\n",
    "    df3['owned_size_exposure'] = df3['Unnamed: 3']\n",
    "    df3['owned_other_size_size'] = df3['Unnamed: 4']\n",
    "    df3['owned_other_size_unit'] = df3['Unnamed: 5']\n",
    "    df3['owned_other_size_exposure'] = df3['Unnamed: 6']\n",
    "    df3 = df3[['REITS','segment','country','state','city','number','owned_size_size','owned_size_exposure','owned_other_size_size',\n",
    "          'owned_other_size_unit','owned_other_size_exposure']]\n",
    "    df3['file'] = f\n",
    "    dfList.append(df3) \n",
    "\n",
    "appended_data = pd.concat(dfList)\n",
    "appended_data = appended_data.replace(np.nan, '', regex=True)\n",
    "appended_data[\"file\"] = appended_data[\"file\"].str.split(\"Asia\", expand=True)[1]\n",
    "appended_data['city'] = appended_data['city'].str[8:]\n",
    "appended_data['country'] = appended_data['country'].replace(' ', '', regex=True)\n",
    "appended_data.to_excel('reits_europe-asia.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "dfList = []\n",
    "fmask = '/home/mila/reit/*.xls*' \n",
    "#newpath = 'C:\\\\Path\\\\To\\\\New\\\\Folder'\n",
    "\n",
    "for f in glob.glob(fmask): \n",
    "    df = pd.read_excel(f)\n",
    "    comp = df.iloc[0,0]\n",
    "    df.dropna(subset = [\"Unnamed: 1\"], inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop([0]).reset_index(drop=True)\n",
    "    df1 = df.loc[df['Unnamed: 0'].str.contains('   ')]\n",
    "    df2 = df.loc[~df['Unnamed: 0'].str.contains('   ')]\n",
    "    l = list(df2.index.values.tolist())\n",
    "    l_mod = [0] + l + [max(l)+len(df)-1]\n",
    "    list_of_dfs = [df.iloc[l_mod[n]:l_mod[n+1]] for n in range(len(l_mod)-1)]\n",
    "    for li in np.arange(1,(len(l)+1)):\n",
    "        list_of_dfs[li]['segment'] = list_of_dfs[li].iloc[0,0]\n",
    "        list_of_dfs[li] = list_of_dfs[li].reset_index(drop=True)\n",
    "        list_of_dfs[li] = list_of_dfs[li].drop([0])\n",
    "    df3 = pd.concat(list_of_dfs).reset_index(drop=True)\n",
    "    df3['MSA'] = df3['Unnamed: 0']\n",
    "    df3['country'] = 'USA'\n",
    "\n",
    "    df3[['city','state']] = df3['MSA'].str.split(', ',expand=True)\n",
    "    \n",
    "    if (df3['state'].str.contains('USA')).any():\n",
    "        df3['country'] = df3['state']\n",
    "        df3['state'] = df3['city']\n",
    "        df3['city'] = ''\n",
    "     \n",
    "    if (df3['country'].str.contains('USA')==False).any():\n",
    "        df3['city'] = df3['state']\n",
    "        df3['state'] = ''\n",
    "        \n",
    "    if (df3['state'].str.contains('Canada')).any():\n",
    "        df3['country'] = df3['state']\n",
    "        df3['state'] = ''\n",
    "    \n",
    "\n",
    "    df3['REITS'] = comp\n",
    "    df3[\"REITS\"] = df3[\"REITS\"].str.split(\"|\", expand=True)[0]\n",
    "    df3['number'] = df3['Unnamed: 1']\n",
    "    df3['owned_size_size'] = df3['Unnamed: 2']\n",
    "    df3['owned_size_exposure'] = df3['Unnamed: 3']\n",
    "    df3['owned_other_size_size'] = df3['Unnamed: 4']\n",
    "    df3['owned_other_size_unit'] = df3['Unnamed: 5']\n",
    "    df3['owned_other_size_exposure'] = df3['Unnamed: 6']\n",
    "    df3 = df3[['REITS','segment','country','state','city','number','owned_size_size','owned_size_exposure','owned_other_size_size',\n",
    "          'owned_other_size_unit','owned_other_size_exposure']]\n",
    "    df3['file'] = f\n",
    "    dfList.append(df3)\n",
    "    \n",
    "appended_data = pd.concat(dfList).reset_index(drop=True)\n",
    "appended_data['state'] = appended_data['state'].replace(np.nan, 'rho', regex=True)\n",
    "appended_data.loc[appended_data.index[appended_data['state'].str.contains('rho')].tolist(),'country']=appended_data['city']\n",
    "appended_data.loc[appended_data.index[appended_data['state'].str.contains('rho')].tolist(),'city']=''\n",
    "appended_data.loc[appended_data.index[appended_data['state'].str.contains('rho')].tolist(),'state']=''\n",
    "appended_data[\"file\"] = appended_data[\"file\"].str.split(\"reit\", expand=True)[1]\n",
    "appended_data['city'] = appended_data['city'].str[8:]\n",
    "appended_data['country'] = appended_data['country'].replace(' ', '', regex=True)\n",
    "appended_data['state'] = appended_data['state'].replace(' ', '', regex=True)\n",
    "appended_data.to_excel('reit.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfList = []\n",
    "fmask = '/home/mila/reit/Europe_Asia/spec/states/*.xls*' \n",
    "#newpath = 'C:\\\\Path\\\\To\\\\New\\\\Folder'\n",
    "\n",
    "for f in glob.glob(fmask): \n",
    "    df = pd.read_excel(f)\n",
    "    comp = df.iloc[0,0]\n",
    "    df.dropna(subset = [\"Unnamed: 1\"], inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop([0]).reset_index(drop=True)\n",
    "    df1 = df.loc[df['Unnamed: 0'].str.contains('   ')]\n",
    "    df2 = df.loc[~df['Unnamed: 0'].str.contains('   ')]\n",
    "    l = list(df2.index.values.tolist())\n",
    "    l_mod = [0] + l + [max(l)+len(df)-1]\n",
    "    list_of_dfs = [df.iloc[l_mod[n]:l_mod[n+1]] for n in range(len(l_mod)-1)]\n",
    "    for li in np.arange(1,(len(l)+1)):\n",
    "        list_of_dfs[li]['segment'] = list_of_dfs[li].iloc[0,0]\n",
    "        list_of_dfs[li] = list_of_dfs[li].reset_index(drop=True)\n",
    "        list_of_dfs[li] = list_of_dfs[li].drop([0])\n",
    "    df3 = pd.concat(list_of_dfs).reset_index(drop=True)\n",
    "    df3['MSA'] = df3['Unnamed: 0']\n",
    "    #not USA\n",
    "    df4 = df3[df3['MSA'].str.contains('USA')==False]\n",
    "    if  (df4['MSA'].str.contains(',')).any():\n",
    "        df4[['city','country']] = df4['MSA'].str.split(', ',expand=True)\n",
    "        df4['state'] = 0\n",
    "        df4.loc[df4.index[df4['country'].isnull()].tolist(),'state'] = df4['city']\n",
    "        df4.loc[df4.index[df4['country'].isnull()].tolist(),'city'] = ' '\n",
    "        df4.loc[df4.index[df4['country'].isnull()].tolist(),'country'] = df4['state']\n",
    "        df4['state'] = ''\n",
    "    elif (df4['MSA'].str.contains(',')==False).any():\n",
    "        df4['country'] = df4['MSA']\n",
    "        df4['state'] = ''\n",
    "        df4['city'] = ''\n",
    "    #USA\n",
    "    if (df3['MSA'].str.contains('USA')).any():\n",
    "        df5 = df3[df3['MSA'].str.contains('USA')]\n",
    "        df5[['city','state','country']] = df5['MSA'].str.split(', ',expand=True)\n",
    "        df5 = df5.replace(np.nan, '', regex=True)\n",
    "        df5.loc[df5.index[df5['state'].str.contains('USA')].tolist(),'country']=df5['state']\n",
    "        df5['state_add']=df5['state']\n",
    "        df5.loc[df5.index[df5['state_add'].str.contains('USA')].tolist(),'state']=df5['city']\n",
    "        df5.loc[df5.index[df5['state_add'].str.contains('USA')].tolist(),'city']=' '\n",
    "        del df5['state_add']\n",
    "        df5.loc[df5.index[df5['city'].str.contains('USA')].tolist(),'country']=df5['city']\n",
    "        df5.loc[df5.index[df5['city'].str.contains('USA')].tolist(),'city']=' '\n",
    "        df3 = df5.append(df4, ignore_index=True)\n",
    "    elif (df3['MSA'].str.contains('USA')==False).any():\n",
    "        df3 = df4\n",
    "    \n",
    "    df3['REITS'] = comp\n",
    "    #df3[\"REITS\"] = df3[\"REITS\"].str.split(\"|\", expand=True)[0]\n",
    "    df3['number'] = df3['Unnamed: 1']\n",
    "    df3['owned_size_size'] = df3['Unnamed: 2']\n",
    "    df3['owned_size_exposure'] = df3['Unnamed: 3']\n",
    "    df3['owned_other_size_size'] = df3['Unnamed: 4']\n",
    "    df3['owned_other_size_unit'] = df3['Unnamed: 5']\n",
    "    df3['owned_other_size_exposure'] = df3['Unnamed: 6']\n",
    "    df3 = df3[['REITS','segment','country','state','city','number','owned_size_size','owned_size_exposure','owned_other_size_size',\n",
    "          'owned_other_size_unit','owned_other_size_exposure']]\n",
    "    df3['file'] = f\n",
    "    dfList.append(df3) \n",
    "\n",
    "appended_data = pd.concat(dfList)\n",
    "appended_data = appended_data.replace(np.nan, '', regex=True)\n",
    "appended_data[\"file\"] = appended_data[\"file\"].str.split(\"Asia\", expand=True)[1]\n",
    "appended_data['city'] = appended_data['city'].str[8:]\n",
    "appended_data['country'] = appended_data['country'].replace(' ', '', regex=True)\n",
    "appended_data.to_excel('reits_europe-asia1.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
